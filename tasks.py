import gym
import h5py
import numpy as np
import matplotlib.pylab as plt
import random
from sklearn.cluster import MiniBatchKMeans
from PIL import Image

"""
This function stores to a file the frame generated by the openai-gym environment specified with env
env : environment
episodes : Number of games to store. A game is completed when the environment return's done as true in env.step
policy : This should be a function that takes as input the frame and outputs an action. For a random policy the input is not 
used but should be declared nonetheless
filename: Name of the filename where is going to be stored the data
colorMode: Indicates whether to store the images in gray scale or RGB
"""

def gatherData(env, episodes, policy, filename, colorMode = 'gray'):
	f = filename

	for episode in range(episodes):
		env.reset()	

		episodeNumber = f.create_group("episode" + str(episode))
		iterations = []
		images = []
		rewards = []
		finished = []
		i = 0

		while (True):
			env.render()

			randomAction = env.action_space.sample()
			observation, reward, done, info = env.step(randomAction)

			iterations.append(i)
			images.append(observation)
			rewards.append(reward)
			finished.append(done)

			i = i + 1

			#Resets if done
			if (done):
				i = 0
				iters = episodeNumber.create_dataset("iteration" + str(episode), data = iterations)
				im = episodeNumber.create_dataset("image" + str(episode), data = images)
				rew = episodeNumber.create_dataset("reward" + str(episode), data = rewards)
				fin = episodeNumber.create_dataset("finished" + str(episode), data = finished)
				break	

#Loads images into memory from an episode
def readData(filename, episode):
	f = filename

	episodeName = "/episode" + str(episode)
	imageName = episodeName + '/image' + str(episode)
	ep = f.get(episodeName)
	images = ep.get(imageName)
	return np.array(images)
			
"""
Visualizes specified number of random frames 
and prints the size of the datasets. 
"""
def testAndVisualizeData(filename, episode, numImages):

	f = filename
	images = readData(filename, episode)
	print("Data size: " + str(len(images)))
	try: 
		imageSampleIndices = random.sample(range(0,len(images)),numImages)
	except ValueError:
		print("Your image subset is too big! Try a smaller number.")
		return

	for index in imageSampleIndices:
		print(images[index])
		plt.imshow(images[index])
		plt.show()

def getImages(filename):
	f = filename
	images = []
	numEpisodes = len(f.keys())
	for episode in range(numEpisodes):
		image = readData(f, episode)
		images.append(image)

	return images

"""
filename: h5py filename 
rangeOfCluster: Tuple of form (start, stop, step) Start is the number of clusters to start the search, stop the number of clusters where the search stops.
graph: Whether to visualize or not performance of the clustering over the search
method: specifies the clustering algorithm to be used

OUTPUTS

performanceCurve: Numpy array with Number of clusters vs performance metric 
centroids: Numpy array with the centroids this should be at max in the thousands range
"""
def imageClusterSearch(filename, rangeOfClusters, graph, method):
	f = filename
	images = getImages(f)
	image = images[0][0]
	img = Image.fromarray(image)
	img = img.resize([84,84]).convert('L')

	performanceCurve = []
	start, stop, step = rangeOfClusters
	print(img)
	"""
	if (method == "MiniBatchKMeans"):
		mbk = MiniBatchKMeans()
		centroids = mbk.partial_fit(images[0])
	return centroids
	"""

######################
##TESTS
######################

def testGatherData():
	testEnv = gym.make('Enduro-v0')
	episodes = 5
	dummyPolicy = ""
	testFile = h5py.File("test.hdf5", "w")
	gatherData(testEnv, episodes, dummyPolicy, testFile, 'gray')
	for val in testFile.values():
		print(val.name)
		for dset in val.values():
			print(dset.name)
			for i in range(len(dset)):
				print dset[i],
			print("")
		print("")

def testGetImages():
	testFile = h5py.File("test.hdf5", "a")
	images = getImages(testFile)
	print(images[0][0])

def testReadData():
	testFile = h5py.File("test.hdf5", "a")
	episode = 0
	images = readData(testFile, episode)
	print(images)

def testTestAndVisualizeData():
	testFile = h5py.File("test.hdf5", "a")
	episode = 0
	numImages = 5
	testAndVisualizeData(testFile, episode, numImages)

def testImageClusterSearch():
	testFile = h5py.File("test.hdf5", "a")
	start = 1
	stop = 20
	step = 1
	visualizeGraph = False
	method = "MiniBatchKMeans" #TODO: change to a function
	rangeOfClusters = (start, stop, step)
	print(imageClusterSearch(testFile, rangeOfClusters, visualizeGraph, method))

def testAll():
	#testGatherData()
	#testReadData()
	#testTestAndVisualizeData()
	#testGetImages()
	testImageClusterSearch()

if __name__ == "__main__":
	testAll()


